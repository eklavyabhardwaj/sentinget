{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739b4e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of ReportDetailsNode1:\n",
      "              TestID InstruID   BrandName ModelNumber    CompName  DeptName  \\\n",
      "0  1_18032025_100544   RD1234  Electrolab    Sentinai  Electrolab  Research   \n",
      "1  2_18032025_100604   RD1234  Electrolab    Sentinai  Electrolab  Research   \n",
      "2  3_18032025_100625   RD1234  Electrolab    Sentinai  Electrolab  Research   \n",
      "3  4_18032025_100638   RD1234  Electrolab    Sentinai  Electrolab  Research   \n",
      "4  5_18032025_100927   RD1234  Electrolab    Sentinai  Electrolab  Research   \n",
      "\n",
      "  SerialNumber                                       CapturedData Sync  \n",
      "0      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "1      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "2      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "3      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "4      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "\n",
      "\n",
      "Preview of ReportDetailsNode2:\n",
      "              TestID InstruID   BrandName ModelNumber    CompName  DeptName  \\\n",
      "0  1_20032025_120212    EKF24  Electrolab    Sentinai  Electrolab  Research   \n",
      "1  2_20032025_120327    EKF24  Electrolab    Sentinai  Electrolab  Research   \n",
      "2  3_20032025_120500    EKF24  Electrolab    Sentinai  Electrolab  Research   \n",
      "3  4_20032025_120607    EKF24  Electrolab    Sentinai  Electrolab  Research   \n",
      "4  5_20032025_120839    EKF24  Electrolab    Sentinai  Electrolab  Research   \n",
      "\n",
      "  SerialNumber                                       CapturedData Sync  \n",
      "0      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "1      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "2      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "3      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "4      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "\n",
      "\n",
      "Preview of ReportDetailsNode3:\n",
      "              TestID InstruID   BrandName ModelNumber    CompName  DeptName  \\\n",
      "0  1_20032025_120218    EKF26  Electrolab    Sentinai  Electrolab  Research   \n",
      "1  2_20032025_120348    EKF26  Electrolab    Sentinai  Electrolab  Research   \n",
      "2  3_20032025_120511    EKF26  Electrolab    Sentinai  Electrolab  Research   \n",
      "3  4_20032025_120627    EKF26  Electrolab    Sentinai  Electrolab  Research   \n",
      "4  5_20032025_120849    EKF26  Electrolab    Sentinai  Electrolab  Research   \n",
      "\n",
      "  SerialNumber                                       CapturedData Sync  \n",
      "0      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "1      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "2      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "3      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "4      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "\n",
      "\n",
      "Preview of ReportDetailsNode4:\n",
      "              TestID InstruID   BrandName ModelNumber    CompName  DeptName  \\\n",
      "0  1_20032025_124838    EKF26  Electrolab    Sentinai  Electrolab  Research   \n",
      "1  2_20032025_125610    EKF26  Electrolab    Sentinai  Electrolab  Research   \n",
      "2  3_20032025_130228    EKF26  Electrolab    Sentinai  Electrolab  Research   \n",
      "3  4_20032025_130612    EKF26  Electrolab    Sentinai  Electrolab  Research   \n",
      "4  5_20032025_131220    EKF26  Electrolab    Sentinai  Electrolab  Research   \n",
      "\n",
      "  SerialNumber                                       CapturedData Sync  \n",
      "0      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "1      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "2      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "3      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "4      1234567  \\r\\r\\n\\r\\r\\n\\r\\r\\n                            ...    1  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "connection = sqlite3.connect('ReportData.db')\n",
    "\n",
    "\"\"\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "\n",
    "for i, table in enumerate(tables):\n",
    "    table_name = table[0]  \n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    df = pd.read_sql(query, connection)\n",
    "    \n",
    "\n",
    "    globals()[f\"df{i+1}\"] = df\n",
    "\n",
    "    print(f\"Preview of {table_name}:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77689a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter the DataFrame for the specific TestID\n",
    "# captured_data = df2.loc[df2['TestID'] == '1_17032025_161954', 'CapturedData']\n",
    "\n",
    "# # Print the captured data; using .iloc[0] to get the first matching row\n",
    "# print(\"Captured Data for TestID 1_17032025_161954:\")\n",
    "# print(captured_data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69b2b69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the Node: 1\n",
      "Enter TestID: 2_18032025_100604\n",
      "Captured Data for TestID 2_18032025_100604:\n",
      "\n",
      "\n",
      "\n",
      "                            ELECTROLAB INDIA Pvt. Ltd.                     \n",
      "     ----------------------------------------------------------------------\n",
      "                                    EKF-25                                 \n",
      "     ----------------------------------------------------------------------\n",
      "                                Report Details                             \n",
      "     ----------------------------------------------------------------------\n",
      "     Kloudface  Details:                                                   \n",
      "     ----------------------------------------------------------------------\n",
      "     Instrument ID : INSTRUMENT        Brand           : ELECTROLAB        \n",
      "     Serial No.    : 2211023           Model No.       : EKF-25            \n",
      "     IP Address    : 192.168.6.141     Firmware Version: v1.0              \n",
      "     Company       : ELECTROLAB        Department      : RND               \n",
      "     ----------------------------------------------------------------------\n",
      "\n",
      "     Parent Instrument Details:                                            \n",
      "     ----------------------------------------------------------------------\n",
      "     Model No.       : EF2W              Serial Number  : 2401001           \n",
      "     Firmware Version: v3.0              Instrument ID  : EF-2W V3.0        \n",
      "     ----------------------------------------------------------------------\n",
      "\n",
      "     User Details:                                                         \n",
      "     ----------------------------------------------------------------------\n",
      "     User          : ADMIN               Role           : RAdmin            \n",
      "     Group         : ADMIN             \n",
      "     ----------------------------------------------------------------------\n",
      "\n",
      "     Product Details:                                                      \n",
      "     ----------------------------------------------------------------------\n",
      "     Product Name  : YHG               \n",
      "     Drum Type     : Abrasion          \n",
      "     RPM           : 25                No. of Drums     : 2                 \n",
      "     Run Mode      : Count             Set Count        : 0127              \n",
      "     Fr.Limit(%W/W): NMT 1.0               \n",
      "     ----------------------------------------------------------------------\n",
      "\n",
      "     Test Details:                                                         \n",
      "     ----------------------------------------------------------------------\n",
      "     Test ID          : 00172 06022025_095214\n",
      "     AR No. D1        : DBBBVVCCXZAQQWWE\n",
      "     Batch No. D1     : SSZXCCVBNN\n",
      "     AR No. D2        : NNNBBVVCCXXZDFGH\n",
      "     Batch No. D2     : BNVCCXAS\n",
      "     Start Date & time: 06/02/2025        09:52:14          \n",
      "     End Date & time  : 06/02/2025        09:57:25          \n",
      "     Halt Time        : 00:00:00          \n",
      "     Weighing Scale   : MANUAL            \n",
      "     ----------------------------------------------------------------------\n",
      "\n",
      "     RPM History    :                                                      \n",
      "     ----------------------------------------\n",
      "     |      INTERVAL     |        RPM       |\n",
      "     ________________________________________\n",
      "     |         0012      |      025.0       |\n",
      "     |______________________________________|\n",
      "     |         0024      |      025.1       |\n",
      "     |______________________________________|\n",
      "     |         0036      |      025.1       |\n",
      "     |______________________________________|\n",
      "     |         0048      |      025.1       |\n",
      "     |______________________________________|\n",
      "     |         0060      |      025.0       |\n",
      "     |______________________________________|\n",
      "     |         0072      |      025.1       |\n",
      "     |______________________________________|\n",
      "     |         0084      |      025.1       |\n",
      "     |______________________________________|\n",
      "     |         0096      |      025.1       |\n",
      "     |______________________________________|\n",
      "     |         0108      |      025.1       |\n",
      "     |______________________________________|\n",
      "     |         0120      |      025.1       |\n",
      "     |______________________________________|\n",
      "\n",
      "\n",
      "     Test Calculations :                                                   \n",
      "     ----------------------------------------------------------------------\n",
      "            Drum 1                                     Drum 2                    \n",
      "     Wgt Before test(g) : 9.0000            Wgt Before test(g) : 4.0000            \n",
      "     Wgt After test(g)  : 8.0000            Wgt After test(g)  : 4.0000            \n",
      "     Friability(%)      : 11.1111           Friability(%)      : 0.0000            \n",
      "     Result             : Fail              Result             : Pass              \n",
      "     ----------------------------------------------------------------------\n",
      "\n",
      "     Formula :                                                     \n",
      "     ----------------------------------------------------------------------\n",
      "              | Ini. Weight   -   Fin. Weight |  *100         \n",
      "     F(%) =   ___________________________________________         \n",
      "                        | Ini. Weight |                        \n",
      "\n",
      "     ----------------------------------------------------------------------\n",
      "\n",
      "     Test Status       : Test Completed    Test Completed by: ADMIN             \n",
      "     Power Fail Status : No               Comm Fail Status  : No\n",
      "     ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "     Remark        :     \n",
      "\n",
      "     Done By       :                    Date  : \n",
      "\n",
      "     Checked By    :                    Date  : \n",
      "\n",
      "     Reviewed By   :                    Date  : \n",
      "\n",
      "     Approved By   :                    Date  : \n",
      "\n",
      "     E-Signature   :  WJt5ZLmHSiB1VWRwPqNkmuoKvdLO6Q8bRVpvT7BWGHbPbGvJ\n",
      "\n",
      "     TestId        :  00172 06022025_095214\n",
      "     Printed by    :  ADMIN             Print Date  : 28/02/2027 10:06:08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user to select a DataFrame\n",
    "df_choice = input(\"Select the Node: \")\n",
    "\n",
    "# Create a mapping of choices to the DataFrame variables\n",
    "dataframes = {\n",
    "    \"1\": df1,\n",
    "    \"2\": df2,\n",
    "    \"3\": df3,\n",
    "    \"4\": df4\n",
    "}\n",
    "\n",
    "# Get the selected DataFrame based on user input\n",
    "if df_choice in dataframes:\n",
    "    selected_df = dataframes[df_choice]\n",
    "else:\n",
    "    print(\"Invalid DataFrame selection. Please enter 1, 2, 3, or 4.\")\n",
    "    exit()  # Exit the script if an invalid selection is made\n",
    "\n",
    "# Prompt the user to enter a TestID\n",
    "test_id = input(\"Enter TestID: \")\n",
    "\n",
    "# Filter the selected DataFrame for the provided TestID\n",
    "captured_data = selected_df.loc[selected_df['TestID'] == test_id, 'CapturedData']\n",
    "\n",
    "# Check if any matching record exists and print the result accordingly\n",
    "if not captured_data.empty:\n",
    "    print(f\"Captured Data for TestID {test_id}:\")\n",
    "    print(captured_data.iloc[0])\n",
    "else:\n",
    "    print(f\"No captured data found for TestID {test_id} in DataFrame {df_choice}.\")\n",
    "\n",
    "\n",
    "# In[4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2317d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the section name: rpm history\n",
      "Enter column headers separated by commas (e.g., hardness, thickness, diameter, width): interval, rpm\n",
      "Enter the row header column name: \n"
     ]
    }
   ],
   "source": [
    "section = input(\"Enter the section name: \")\n",
    "col_headers_input = input(\"Enter column headers separated by commas (e.g., hardness, thickness, diameter, width): \")\n",
    "col_headers = [col.strip() for col in col_headers_input.split(',')]\n",
    "row_header_col = input(\"Enter the row header column name: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0a7d899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned (with newlines):\n",
      " electrolab india pvt. ltd.                     \n",
      "     \n",
      "                                    ekf25                                 \n",
      "     \n",
      "                                report details                             \n",
      "     \n",
      "     kloudface  details:                                                   \n",
      "     \n",
      "     instrument id : instrument        brand           : electrolab        \n",
      "     serial no.    : 2211023           model no.       : ekf25            \n",
      "     ip address    : 192.168.6.141     firmware version: v1.0              \n",
      "     company       : electrolab        department      : rnd               \n",
      "     \n",
      "     parent instrument details:                                            \n",
      "     \n",
      "     model no.       : ef2w              serial number  : 2401001           \n",
      "     firmware version: v3.0              instrument id  : ef2w v3.0        \n",
      "     \n",
      "     user details:                                                         \n",
      "     \n",
      "     user          : admin               role           : radmin            \n",
      "     group         : admin             \n",
      "     \n",
      "     product details:                                                      \n",
      "     \n",
      "     product name  : yhg               \n",
      "     drum type     : abrasion          \n",
      "     rpm           : 25                no. of drums     : 2                 \n",
      "     run mode      : count             set count        : 0127              \n",
      "     fr.limitww: nmt 1.0               \n",
      "     \n",
      "     test details:                                                         \n",
      "     \n",
      "     test id          : 00172 06022025_095214\n",
      "     ar no. d1        : dbbbvvccxzaqqwwe\n",
      "     batch no. d1     : sszxccvbnn\n",
      "     ar no. d2        : nnnbbvvccxxzdfgh\n",
      "     batch no. d2     : bnvccxas\n",
      "     start date  time: 06022025        09:52:14          \n",
      "     end date  time  : 06022025        09:57:25          \n",
      "     halt time        : 00:00:00          \n",
      "     weighing scale   : manual            \n",
      "     \n",
      "     rpm history    :                                                      \n",
      "     \n",
      "           interval             rpm       \n",
      "     ________________________________________\n",
      "              0012            025.0       \n",
      "     ______________________________________\n",
      "              0024            025.1       \n",
      "     ______________________________________\n",
      "              0036            025.1       \n",
      "     ______________________________________\n",
      "              0048            025.1       \n",
      "     ______________________________________\n",
      "              0060            025.0       \n",
      "     ______________________________________\n",
      "              0072            025.1       \n",
      "     ______________________________________\n",
      "              0084            025.1       \n",
      "     ______________________________________\n",
      "              0096            025.1       \n",
      "     ______________________________________\n",
      "              0108            025.1       \n",
      "     ______________________________________\n",
      "              0120            025.1       \n",
      "     ______________________________________\n",
      "     test calculations :                                                   \n",
      "     \n",
      "            drum 1                                     drum 2                    \n",
      "     wgt before testg : 9.0000            wgt before testg : 4.0000            \n",
      "     wgt after testg  : 8.0000            wgt after testg  : 4.0000            \n",
      "     friability      : 11.1111           friability      : 0.0000            \n",
      "     result             : fail              result             : pass              \n",
      "     \n",
      "     formula :                                                     \n",
      "     \n",
      "               ini. weight      fin. weight   100         \n",
      "     f    ___________________________________________         \n",
      "                         ini. weight                         \n",
      "     \n",
      "     test status       : test completed    test completed by: admin             \n",
      "     power fail status : no               comm fail status  : no\n",
      "     \n",
      "     remark        :     \n",
      "     done by       :                    date  : \n",
      "     checked by    :                    date  : \n",
      "     reviewed by   :                    date  : \n",
      "     approved by   :                    date  : \n",
      "     esignature   :  wjt5zlmhsib1vwrwpqnkmuokvdlo6q8brvpvt7bwghbpbgvj\n",
      "     testid        :  00172 06022025_095214\n",
      "     printed by    :  admin             print date  : 28022027 10:06:08\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 0) Start from your raw CapturedData cell\n",
    "raw = captured_data.iloc[0]\n",
    "\n",
    "# 1) Replace literal crlf/<CR><LF> with real newlines\n",
    "clean = re.sub(r'<CR><LF>|crlf', '\\n', raw, flags=re.IGNORECASE)\n",
    "\n",
    "# 2) Remove <HT> tabs and any 'nul' markers\n",
    "clean = re.sub(r'<HT>', '\\t', clean)\n",
    "clean = re.sub(r'\\bnul\\b', '', clean, flags=re.IGNORECASE)\n",
    "\n",
    "# 3) Remove any other nonâ€‘printables but keep letters, digits, dot, colon, space, tab, newline\n",
    "clean = re.sub(r'[^\\w\\.\\:\\n\\t ]+', '', clean)\n",
    "\n",
    "# 4) Collapse multiple blank lines into one\n",
    "clean = re.sub(r'\\n+', '\\n', clean).strip()\n",
    "\n",
    "# 5) (Optional) lowercase everything\n",
    "cleaned_data = clean.lower()\n",
    "\n",
    "\n",
    "print(\"Cleaned (with newlines):\\n\", cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9be00a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_token(token):\n",
    "    # Remove spaces and dots for a simplified comparison.\n",
    "    # You can customize this further as needed.\n",
    "    return re.sub(r'\\s+|\\.', '', token.lower())\n",
    "\n",
    "def extract_table_from_flat_text(text,\n",
    "                                 section,\n",
    "                                 col_headers,\n",
    "                                 units=None,\n",
    "                                 table_type='normal',\n",
    "                                 row_header_col=None):\n",
    "    # Normalize newlines\n",
    "    text = re.sub(r'\\r\\n|\\r', '\\n', text)\n",
    "    text_lower = text.lower()\n",
    "    sec_lower  = section.lower()\n",
    "\n",
    "    # Find the section start\n",
    "    idx = text_lower.find(sec_lower)\n",
    "    if idx == -1:\n",
    "        print(f\"Section '{section}' not found.\")\n",
    "        return None\n",
    "    lines = text[idx:].strip().split('\\n')\n",
    "\n",
    "    # Prepare normalized version of expected headers\n",
    "    normalized_expected = [normalize_token(h) for h in col_headers]\n",
    "    header_idx = None\n",
    "\n",
    "    # Locate header line with normalization\n",
    "    for i, line in enumerate(lines):\n",
    "        toks = line.strip().split()\n",
    "        # Normalize each token\n",
    "        normalized_toks = [normalize_token(t) for t in toks]\n",
    "\n",
    "        if table_type == 'normal':\n",
    "            # Check if all expected headers appear in the normalized token list\n",
    "            if all(exp_header in normalized_toks for exp_header in normalized_expected):\n",
    "                header_idx = i\n",
    "                break\n",
    "        else:  # for matrix type tables\n",
    "            if normalized_toks == normalized_expected:\n",
    "                header_idx = i\n",
    "                break\n",
    "            # If there's a row header plus the expected columns\n",
    "            if (len(normalized_toks) >= len(normalized_expected) + 1 and\n",
    "                normalized_toks[1:1+len(normalized_expected)] == normalized_expected):\n",
    "                header_idx = i\n",
    "                break\n",
    "\n",
    "    if header_idx is None:\n",
    "        print(f\"Could not locate header line for section '{section}'.\")\n",
    "        return None\n",
    "\n",
    "    # Parse the data rows after the header line\n",
    "    data_lines = lines[header_idx+1:]\n",
    "    number_re = re.compile(r'^[+-]?\\d+(?:\\.\\d+)?$')\n",
    "    rows = []\n",
    "\n",
    "    for line in data_lines:\n",
    "        tokens = line.strip().split()\n",
    "        if not tokens:\n",
    "            continue\n",
    "\n",
    "        if table_type == 'normal':\n",
    "            nums = [t for t in tokens if number_re.match(t)]\n",
    "            if len(nums) == len(col_headers):\n",
    "                rows.append(nums)\n",
    "        else:  # For matrix table type\n",
    "            j = next((i for i, t in enumerate(tokens) if number_re.match(t)), None)\n",
    "            if j is None:\n",
    "                continue\n",
    "            nums = tokens[j:j+len(col_headers)]\n",
    "            if len(nums) == len(col_headers) and all(number_re.match(x) for x in nums):\n",
    "                row_label = \" \".join(tokens[:j])\n",
    "                rows.append([row_label] + nums)\n",
    "\n",
    "    # Build DataFrame\n",
    "    if table_type == 'normal':\n",
    "        df = pd.DataFrame(rows, columns=col_headers)\n",
    "        if units:\n",
    "            df_units = pd.DataFrame([units], columns=col_headers)\n",
    "            df = pd.concat([df_units, df], ignore_index=True)\n",
    "        return df\n",
    "    else:\n",
    "        if not row_header_col:\n",
    "            raise ValueError(\"`row_header_col` is required for matrix tables.\")\n",
    "        cols = [row_header_col] + col_headers\n",
    "        return pd.DataFrame(rows, columns=cols).set_index(row_header_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b55db3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   interval     rpm\n",
      "0      0012   025.0\n",
      "1      0024   025.1\n",
      "2      0036   025.1\n",
      "3      0048   025.1\n",
      "4      0060   025.0\n",
      "5      0072   025.1\n",
      "6      0084   025.1\n",
      "7      0096   025.1\n",
      "8      0108   025.1\n",
      "9      0120   025.1\n",
      "10        1       2\n",
      "11   9.0000  4.0000\n",
      "12   8.0000  4.0000\n",
      "13  11.1111  0.0000\n",
      "   interval     rpm\n",
      "0      0012   025.0\n",
      "1      0024   025.1\n",
      "2      0036   025.1\n",
      "3      0048   025.1\n",
      "4      0060   025.0\n",
      "5      0072   025.1\n",
      "6      0084   025.1\n",
      "7      0096   025.1\n",
      "8      0108   025.1\n",
      "9      0120   025.1\n",
      "10        1       2\n",
      "11   9.0000  4.0000\n",
      "12   8.0000  4.0000\n",
      "13  11.1111  0.0000\n"
     ]
    }
   ],
   "source": [
    "# Default to 'normal' table if row_header_col is not provided or is empty\n",
    "if not row_header_col:\n",
    "    table_type = 'normal'\n",
    "    df_stats = extract_table_from_flat_text(\n",
    "        text=cleaned_data,\n",
    "        section=section,\n",
    "        col_headers=col_headers,\n",
    "        table_type=table_type\n",
    "    )\n",
    "else:\n",
    "    table_type = 'matrix'\n",
    "    df_stats = extract_table_from_flat_text(\n",
    "        text=cleaned_data,\n",
    "        section=section,\n",
    "        col_headers=col_headers,\n",
    "        table_type=table_type,\n",
    "        row_header_col=row_header_col\n",
    "    )\n",
    "\n",
    "# Print and assign to df_main if not already defined\n",
    "print(df_stats)\n",
    "if df_stats is not None and ('df_main' not in locals() or df_main is None):\n",
    "    df_main = df_stats.copy()\n",
    "    print(df_main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5033a7",
   "metadata": {},
   "source": [
    "### Normal Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f34365c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: extract the Test Results section as a normal table\n",
    "# df_stats = extract_table_from_flat_text(\n",
    "#     text=cleaned_data,\n",
    "#     section=section,\n",
    "#     col_headers=col_headers,\n",
    "#     table_type='normal'\n",
    "# )\n",
    "\n",
    "# print(df_stats)\n",
    "# if df_stats is not None and 'df_main' not in locals():\n",
    "#     df_main = df_stats.copy()\n",
    "#     print(df_main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db704b0",
   "metadata": {},
   "source": [
    "### Matric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68720e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_stats = extract_table_from_flat_text(\n",
    "#     text=cleaned_data,\n",
    "#     section=section,\n",
    "#     col_headers=col_headers,\n",
    "#     table_type='matrix',\n",
    "#     row_header_col=row_header_col\n",
    "# )\n",
    "\n",
    "# print(df_stats)\n",
    "# if df_stats is not None and df_main is None:\n",
    "#     df_main = df_stats.copy()\n",
    "#     print(df_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "601bc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_stats is not None and 'df_main' not in locals():\n",
    "    df_main = df_stats.copy()\n",
    "    print(df_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7728ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Call the function to extract the \"Run Parameters\" section as a table\n",
    "# df_stats = extract_table_from_flat_text(\n",
    "#     text=cleaned_data,\n",
    "#     section=\"rpm history\",\n",
    "#     col_headers=[\n",
    "# \"interval\" ,\"rpm\"\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Print the extracted DataFrame\n",
    "# print(df_stats)\n",
    "\n",
    "# if df_stats is not None and not df_stats.empty:\n",
    "#     df_main = df_stats.copy()\n",
    "#     print(df_main)\n",
    "# else:\n",
    "#     print(\"df_stats is None or empty. Ignoring.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730a539",
   "metadata": {},
   "source": [
    "### Table without header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d10dae18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  interval   rpm\n",
      "0     0012  None\n",
      "1     0024  None\n",
      "2     0036  None\n",
      "3     0048  None\n",
      "4     0060  None\n",
      "5     0072  None\n",
      "6     0084  None\n",
      "7     0096  None\n",
      "8     0108  None\n",
      "9     0120  None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_measurement_values(text, section, col_headers):\n",
    "    try:\n",
    "        # Normalize newlines\n",
    "        text = re.sub(r'\\r\\n|\\r', '\\n', text)\n",
    "        text_lower = text.lower()\n",
    "        sec_lower = section.lower()\n",
    "\n",
    "        # Find the start of the section\n",
    "        idx = text_lower.find(sec_lower)\n",
    "        if idx == -1:\n",
    "            print(f\"Section '{section}' not found.\")\n",
    "            return None\n",
    "        lines = text[idx:].strip().split('\\n')\n",
    "\n",
    "        # Parse the data lines after the section header\n",
    "        data_lines = lines[1:]  # Skip the first line which is the header\n",
    "        rows = []\n",
    "\n",
    "        for line in data_lines:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                # Extract the data based on column count\n",
    "                match = re.match(r'(\\d+)\\s*(:\\s*(\\d+))?', line)\n",
    "                if match:\n",
    "                    # Extracting the first column as \"Measurement Number\"\n",
    "                    row_data = [match.group(1)]\n",
    "                    if match.group(3):  # If there is a value after ':'\n",
    "                        row_data.append(int(match.group(3)))\n",
    "                    else:\n",
    "                        row_data.append(None)  # Placeholder for missing value\n",
    "                    rows.append(row_data)\n",
    "\n",
    "        # Create a DataFrame from the extracted rows and user-defined column names\n",
    "        df = pd.DataFrame(rows, columns=col_headers)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define your custom column names here, they can be more than two columns\n",
    "col_headers = col_headers\n",
    "\n",
    "meas_section = section\n",
    "df_stats = extract_measurement_values(cleaned_data, meas_section, col_headers)\n",
    "\n",
    "print(df_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7dd31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_stats is not None and 'df_main' not in locals():\n",
    "    df_main = df_stats.copy()\n",
    "    print(df_main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a694eb3",
   "metadata": {},
   "source": [
    "### Method for nested table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "623188b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Cleaned Captured Data:\n",
      "electrolab india pvt. ltd. ekf 25 report details kloudface details: instrument id : instrument brand : electrolab serial no. : 2211023 model no. : ekf 25 ip address : 192.168.6.141 firmware version: v1.0 company : electrolab department : rnd parent instrument details: model no. : ef2w serial number : 2401001 firmware version: v3.0 instrument id : ef 2w v3.0 user details: user : admin role : radmin group : admin product details: product name : yhg drum type : abrasion rpm : 25 no. of drums : 2 run mode : count set count : 0127 fr.limit w/w : nmt 1.0 test details: test id : 00172 06022025 095214 ar no. d1 : dbbbvvccxzaqqwwe batch no. d1 : sszxccvbnn ar no. d2 : nnnbbvvccxxzdfgh batch no. d2 : bnvccxas start date time: 06/02/2025 09:52:14 end date time : 06/02/2025 09:57:25 halt time : 00:00:00 weighing scale : manual rpm history : interval rpm 0012 025.0 0024 025.1 0036 025.1 0048 025.1 0060 025.0 0072 025.1 0084 025.1 0096 025.1 0108 025.1 0120 025.1 test calculations : drum 1 drum 2 wgt before test g : 9.0000 wgt before test g : 4.0000 wgt after test g : 8.0000 wgt after test g : 4.0000 friability : 11.1111 friability : 0.0000 result : fail result : pass formula : ini. weight fin. weight 100 f ini. weight test status : test completed test completed by: admin power fail status : no comm fail status : no remark : done by : date : checked by : date : reviewed by : date : approved by : date : e signature : wjt5zlmhsib1vwrwpqnkmuokvdlo6q8brvpvt7bwghbpbgvj testid : 00172 06022025 095214 printed by : admin print date : 28/02/2027 10:06:08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Get the captured data as a string\n",
    "raw_data = captured_data.iloc[0]\n",
    "\n",
    "# Step 1: Remove all HTML-like tags (e.g., <CR><LF>, <NUL>, etc.)\n",
    "cleaned_data = re.sub(r'<[^>]+>', '', raw_data)\n",
    "\n",
    "# Step 2: Replace all characters except letters, digits, spaces, dot (.), slash (/), and colon (:) with space\n",
    "cleaned_data = re.sub(r'[^A-Za-z0-9\\s./:]+', ' ', cleaned_data)\n",
    "\n",
    "# Step 3: Replace multiple spaces with a single space\n",
    "cleaned_data = re.sub(r'\\s+', ' ', cleaned_data)\n",
    "\n",
    "# Step 4: Strip leading/trailing spaces\n",
    "cleaned_data = cleaned_data.strip()\n",
    "\n",
    "# Step 5: Convert to lowercase\n",
    "cleaned_data = cleaned_data.lower()\n",
    "\n",
    "# Print the fully cleaned data\n",
    "print(\"Fully Cleaned Captured Data:\")\n",
    "print(cleaned_data)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "658ff5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_table_from_flat_text(text, section, headers, units=None):\n",
    "    # Normalize text: lowercase and replace multiple spaces with one\n",
    "    text = re.sub(r'\\s+', ' ', text.lower())\n",
    "\n",
    "    # Find the section\n",
    "    section_start = text.find(section.lower())\n",
    "    if section_start == -1:\n",
    "        print(f\"Section '{section}' not found.\")\n",
    "        return None\n",
    "\n",
    "    # Get the part after the section header\n",
    "    section_text = text[section_start:]\n",
    "\n",
    "    # Adjust regex to capture the run parameters based on your data format\n",
    "    # The pattern now expects 17 columns, including the interval, time, rpm, and 12 'blx' columns\n",
    "    row_pattern = r'(\\d+)\\s+(\\d{3}:\\d{2})\\s+(\\d+\\.\\d+)\\s+([\\d\\.]+(?:\\s+[\\d\\.]+){13})'\n",
    "\n",
    "    matches = re.findall(row_pattern, section_text)\n",
    "\n",
    "    # If no matches were found, print a message\n",
    "    if not matches:\n",
    "        print(f\"No data matched the pattern in section '{section}'.\")\n",
    "        return None\n",
    "\n",
    "    # Prepare the data in rows based on the matched result\n",
    "    rows = []\n",
    "    for match in matches:\n",
    "        # Combine the match with the other numeric columns into a full row\n",
    "        row = list(match[:3]) + match[3].split()\n",
    "        rows.append(row)\n",
    "\n",
    "    # Ensure the number of columns matches the length of the data\n",
    "    if len(headers) != len(rows[0]):\n",
    "        print(f\"Warning: The number of columns in the headers ({len(headers)}) does not match the extracted data ({len(rows[0])})\")\n",
    "        headers = headers[:len(rows[0])]  # Adjust headers to match the number of columns\n",
    "\n",
    "    # Build the DataFrame from the rows\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "    # If a units row is provided, insert it as the first row of the DataFrame\n",
    "    if units:\n",
    "        unit_df = pd.DataFrame([units], columns=headers)\n",
    "        df = pd.concat([unit_df, df], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6cf8f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data matched the pattern in section 'rpm history'.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Call the function to extract the \"Run Parameters\" section as a table\n",
    "df_stats = extract_table_from_flat_text(\n",
    "    text=cleaned_data,\n",
    "    section=section,\n",
    "    headers=col_headers\n",
    ")\n",
    "\n",
    "# Print the extracted DataFrame\n",
    "print(df_stats) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad680b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_stats is not None and 'df_main' not in locals():\n",
    "    df_main = df_stats.copy()\n",
    "    print(df_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a62ea591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data matched the pattern in section 'rpm history'.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Call the function to extract the \"Run Parameters\" section as a table\n",
    "df_run = extract_table_from_flat_text(\n",
    "    text=cleaned_data,\n",
    "    section=section,\n",
    "    headers=col_headers\n",
    ")\n",
    "\n",
    "# Print the extracted DataFrame\n",
    "print(df_stats) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34b5935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_stats is not None and 'df_main' not in locals():\n",
    "    df_main = df_stats.copy()\n",
    "    print(df_main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83246960",
   "metadata": {},
   "source": [
    "### Auto Extract Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "598fe8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No table data rows found in the provided report text.\n",
      "\n",
      "Extracted DataFrame:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def auto_extract_table(text, col_headers):\n",
    "    \"\"\"\n",
    "    Given a report as free-form text and a list of column headers,\n",
    "    this function scans the text for table rows (assumed to use a pipe '|' delimiter)\n",
    "    and extracts rows that start with a time pattern (HH:MM:SS) as the first column.\n",
    "    Returns a DataFrame with the provided headers.\n",
    "    \"\"\"\n",
    "    # Split into lines\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # Collect candidate table lines: those containing the pipe delimiter and not just dashed lines.\n",
    "    candidate_lines = []\n",
    "    for line in lines:\n",
    "        # Remove leading/trailing spaces and ignore lines that are just a series of dashes.\n",
    "        line_clean = line.strip()\n",
    "        if \"|\" in line_clean and set(line_clean) != {\"-\"}:\n",
    "            candidate_lines.append(line_clean)\n",
    "\n",
    "    # Debugging: show candidate lines\n",
    "    # print(\"Candidate table lines:\")\n",
    "    # for cl in candidate_lines:\n",
    "    #     print(cl)\n",
    "    \n",
    "    # Among these candidate lines, we want to exclude header rows that are not data.\n",
    "    # One common trait in our sample is that data rows start with a time stamp (e.g., \"15:52:56\")\n",
    "    time_pattern = re.compile(r'^\\d{2}:\\d{2}:\\d{2}')\n",
    "    \n",
    "    data_rows = []\n",
    "    for line in candidate_lines:\n",
    "        # Split on pipe delimiter and remove empty entries (from trailing pipes, etc.)\n",
    "        tokens = [token.strip() for token in line.split('|') if token.strip() != '']\n",
    "        # If the first token matches the time pattern, consider this a data row.\n",
    "        if tokens and time_pattern.match(tokens[0]):\n",
    "            data_rows.append(tokens)\n",
    "    \n",
    "    # If no rows were extracted with the time heuristic, as a fallback,\n",
    "    # try filtering by matching the expected number of columns.\n",
    "    if not data_rows:\n",
    "        for line in candidate_lines:\n",
    "            tokens = [token.strip() for token in line.split('|')]\n",
    "            if len(tokens) == len(col_headers):\n",
    "                data_rows.append(tokens)\n",
    "    \n",
    "    if not data_rows:\n",
    "        print(\"No table data rows found in the provided report text.\")\n",
    "        return None\n",
    "\n",
    "    # Optionally, print the extracted rows for debugging\n",
    "    print(\"Extracted Data Rows:\")\n",
    "    for row in data_rows:\n",
    "        print(row)\n",
    "\n",
    "    # Create a DataFrame from the extracted rows,\n",
    "    # using the user-supplied column headers.\n",
    "    # Note: If the number of tokens in a row differs from the length of col_headers,\n",
    "    # additional adjustments may be needed.\n",
    "    df = pd.DataFrame(data_rows, columns=col_headers)\n",
    "    return df\n",
    "\n",
    "# # Filter the DataFrame for the specific TestID\n",
    "# captured_data = df3.loc[df3['TestID'] == '3_17032025_162745', 'CapturedData']\n",
    "\n",
    "# # Print the captured data; using .iloc[0] to get the first matching row\n",
    "# print(\"Captured Data for TestID 3_17032025_162407:\")\n",
    "# print(captured_data.iloc[0])\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# Get the captured data as a string\n",
    "raw_data = captured_data.iloc[0]\n",
    "# User-supplied column headers for the table\n",
    "col_headers = col_headers\n",
    "\n",
    "# Extract the table as a DataFrame\n",
    "df_stats = auto_extract_table(raw_data, col_headers)\n",
    "\n",
    "print(\"\\nExtracted DataFrame:\")\n",
    "print(df_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f08ef157",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_stats is not None and 'df_main' not in locals():\n",
    "    df_main = df_stats.copy()\n",
    "    print(df_main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8650002",
   "metadata": {},
   "source": [
    "### Field Extraction into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "897ca85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electrolab india pvt. ltd. ekf 25 report details kloudface details: instrument id : instrument brand : electrolab serial no. : 2211023 model no. : ekf 25 ip address : 192.168.6.141 firmware version: v1.0 company : electrolab department : rnd parent instrument details: model no. : ef2w serial number : 2401001 firmware version: v3.0 instrument id : ef 2w v3.0 user details: user : admin role : radmin group : admin product details: product name : yhg drum type : abrasion rpm : 25 no. of drums : 2 run mode : count set count : 0127 fr.limit w/w : nmt 1.0 test details: test id : 00172 06022025 095214 ar no. d1 : dbbbvvccxzaqqwwe batch no. d1 : sszxccvbnn ar no. d2 : nnnbbvvccxxzdfgh batch no. d2 : bnvccxas start date time: 06/02/2025 09:52:14 end date time : 06/02/2025 09:57:25 halt time : 00:00:00 weighing scale : manual rpm history : interval rpm 0012 025.0 0024 025.1 0036 025.1 0048 025.1 0060 025.0 0072 025.1 0084 025.1 0096 025.1 0108 025.1 0120 025.1 test calculations : drum 1 drum 2 wgt before test g : 9.0000 wgt before test g : 4.0000 wgt after test g : 8.0000 wgt after test g : 4.0000 friability : 11.1111 friability : 0.0000 result : fail result : pass formula : ini. weight fin. weight 100 f ini. weight test status : test completed test completed by: admin power fail status : no comm fail status : no remark : done by : date : checked by : date : reviewed by : date : approved by : date : e signature : wjt5zlmhsib1vwrwpqnkmuokvdlo6q8brvpvt7bwghbpbgvj testid : 00172 06022025 095214 printed by : admin print date : 28/02/2027 10:06:08\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92201dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electrolab india pvt ltd ekf  report details kloudface details instrument id  instrument brand  electrolab serial no   model no  ekf  ip address   firmware version v company  electrolab department  rnd parent instrument details model no  efw serial number   firmware version v instrument id  ef w v user details user  admin role  radmin group  admin product details product name  yhg drum type  abrasion rpm   no of drums   run mode  count set count   frlimit ww  nmt  test details test id     ar no d  dbbbvvccxzaqqwwe batch no d  sszxccvbnn ar no d  nnnbbvvccxxzdfgh batch no d  bnvccxas start date time   end date time    halt time   weighing scale  manual rpm history  interval rpm                     test calculations  drum  drum  wgt before test g   wgt before test g   wgt after test g   wgt after test g   friability   friability   result  fail result  pass formula  ini weight fin weight  f ini weight test status  test completed test completed by admin power fail status  no comm fail status  no remark  done by  date  checked by  date  reviewed by  date  approved by  date  e signature  wjtzlmhsibvwrwpqnkmuokvdloqbrvpvtbwghbpbgvj testid     printed by  admin print date   \n"
     ]
    }
   ],
   "source": [
    "cleaned_data = re.sub(r'[.:\\\\|/\\d]', '', cleaned_data)\n",
    "\n",
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7963b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   interval     rpm\n",
      "0      0012   025.0\n",
      "1      0024   025.1\n",
      "2      0036   025.1\n",
      "3      0048   025.1\n",
      "4      0060   025.0\n",
      "5      0072   025.1\n",
      "6      0084   025.1\n",
      "7      0096   025.1\n",
      "8      0108   025.1\n",
      "9      0120   025.1\n",
      "10        1       2\n",
      "11   9.0000  4.0000\n",
      "12   8.0000  4.0000\n",
      "13  11.1111  0.0000\n"
     ]
    }
   ],
   "source": [
    "df = df_main.copy()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03701729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the maximum number of rows the table should have: 10\n",
      "The maximum number of rows the table can have is: 10\n"
     ]
    }
   ],
   "source": [
    "# Take input from the user for maximum number of rows in the table\n",
    "max_rows = int(input(\"Enter the maximum number of rows the table should have: \"))\n",
    "\n",
    "# Display the entered value\n",
    "print(f\"The maximum number of rows the table can have is: {max_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9893e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df) > max_rows:\n",
    "    # Drop rows from the bottom\n",
    "    df = df.head(max_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb7952fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   interval rpm\n",
      "0              \n",
      "1              \n",
      "2              \n",
      "3              \n",
      "4              \n",
      "5              \n",
      "6              \n",
      "7              \n",
      "8              \n",
      "9              \n",
      "10             \n",
      "11             \n",
      "12             \n",
      "13             \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean strings\n",
    "def clean_text(s):\n",
    "    if isinstance(s, str):\n",
    "        return re.sub(r'[.:\\\\|/\\d]', '', s)  # Added forward slash /\n",
    "    return s\n",
    "\n",
    "# Clean column headers\n",
    "df_main.columns = [clean_text(col) for col in df_main.columns]\n",
    "\n",
    "# Clean all cell values\n",
    "df_main = df_main.applymap(clean_text)\n",
    "\n",
    "# Print cleaned DataFrame\n",
    "print(df_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be7ae8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electrolab india pvt ltd ekf report details kloudface details instrument id instrument brand electrolab serial no model no ekf ip address firmware version v company electrolab department rnd parent instrument details model no efw serial number firmware version v instrument id ef w v user details user admin role radmin group admin product details product name yhg drum type abrasion no of drums run mode count set count frlimit ww nmt test details test id ar no d dbbbvvccxzaqqwwe batch no d sszxccvbnn ar no d nnnbbvvccxxzdfgh batch no d bnvccxas start date time end date time halt time weighing scale manual history test calculations drum drum wgt before test g wgt before test g wgt after test g wgt after test g friability friability result fail result pass formula ini weight fin weight f ini weight test status test completed test completed by admin power fail status no comm fail status no remark done by date checked by date reviewed by date approved by date e signature wjtzlmhsibvwrwpqnkmuokvdloqbrvpvtbwghbpbgvj testid printed by admin print date\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to remove each occurrence of a word or number using regex with word boundaries.\n",
    "def remove_occurrence(text, item):\n",
    "    # Convert item to string first\n",
    "    item_str = str(item)\n",
    "    pattern = r'\\b' + re.escape(item_str) + r'\\b'\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "# Example cleaned_data (your original full text string)\n",
    "# cleaned_data = \"...\" \n",
    "\n",
    "# Remove each DataFrame index value (e.g. 0, 1, \"average\", etc.)\n",
    "for idx in df_main.index:\n",
    "    cleaned_data = remove_occurrence(cleaned_data, idx)\n",
    "\n",
    "# Remove each DataFrame column header (e.g. \"hardness\", \"thickness\", etc.)\n",
    "for col in df_main.columns:\n",
    "    cleaned_data = remove_occurrence(cleaned_data, col)\n",
    "\n",
    "# Remove each DataFrame cell value\n",
    "for col in df_main.columns:\n",
    "    for val in df_main[col]:\n",
    "        val_str = str(val).strip()\n",
    "        cleaned_data = remove_occurrence(cleaned_data, val_str)\n",
    "\n",
    "# Remove extra whitespace introduced by removals\n",
    "cleaned_data_modified = re.sub(r'\\s+', ' ', cleaned_data).strip()\n",
    "\n",
    "# Optional: print result\n",
    "print(cleaned_data_modified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "187385df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified cleaned_data:\n",
      "electrolab india pvt ltd ekf report details kloudface details instrument id instrument brand electrolab serial no model no ekf ip address firmware version v company electrolab department rnd parent instrument details model no efw serial number firmware version v instrument id ef w v user details user admin role radmin group admin product details product name yhg drum type abrasion no of drums run mode count set count frlimit ww nmt test details test id ar no d dbbbvvccxzaqqwwe batch no d sszxccvbnn ar no d nnnbbvvccxxzdfgh batch no d bnvccxas start date time end date time halt time weighing scale manual history test calculations drum drum wgt before test g wgt before test g wgt after test g wgt after test g friability friability result fail result pass formula ini weight fin weight f ini weight test status test completed test completed by admin power fail status no comm fail status no remark done by date checked by date reviewed by date approved by date e signature wjtzlmhsibvwrwpqnkmuokvdloqbrvpvtbwghbpbgvj testid printed by admin print date\n"
     ]
    }
   ],
   "source": [
    "print(\"Modified cleaned_data:\")\n",
    "print(cleaned_data_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3dbeb6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac9d9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields_list = [\n",
    "#     \"brand\",\n",
    "#     \"model number\",\n",
    "#     \"serial number\",\n",
    "#     \"instrument id\",\n",
    "#     \"company name\",\n",
    "#     \"department\",\n",
    "#     \"user details user\",\n",
    "#     \"role\",\n",
    "#     \"user group\",\n",
    "#     \"product details product name\",\n",
    "#     \"product descr.\",\n",
    "#     \"tablet shape\",\n",
    "#     \"product parameters mode\",\n",
    "#     \"delay\",\n",
    "#     \"method\",\n",
    "#     \"speed\",\n",
    "#     \"back off\",\n",
    "#     \"product units hardness unit\",\n",
    "#     \"hardness precision\",\n",
    "#     \"ud factor\",\n",
    "#     \"weight unit\",\n",
    "#     \"weight precision\",\n",
    "#     \"length unit\",\n",
    "#     \"length precision\",\n",
    "#     \"method details method name\",\n",
    "#     \"hardness samples\",\n",
    "#     \"weight samples\",\n",
    "#     \"thickness samples\",\n",
    "#     \"diameter samples\",\n",
    "#     \"width samples\",\n",
    "#     \"test details test id\",\n",
    "#     \"press identif.\",\n",
    "#     \"batch identif.\",\n",
    "#     \"container number\",\n",
    "#     \"test comment\",\n",
    "#     \"ex. thickness\",\n",
    "#     \"start date/time\",\n",
    "#     \"end date/time\",\n",
    "#     \"print time\"\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "995ad8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields_list = [\"kloudface details brand\",\"model no\",\"brand\",\"model no\",\"instrument id\",\"serial no\",\"fw version\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18f68f4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fields_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Escape the field names to handle any special regex characters\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m pattern_fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(re\u001b[38;5;241m.\u001b[39mescape(field) \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m fields_list)\n\u001b[0;32m      5\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(?i)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpattern_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(.*?)(?=\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(?:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpattern_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*|$)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m matches \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(pattern, cleaned_data_modified, re\u001b[38;5;241m.\u001b[39mDOTALL)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fields_list' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Escape the field names to handle any special regex characters\n",
    "pattern_fields = \"|\".join(re.escape(field) for field in fields_list)\n",
    "pattern = rf'(?i)\\b({pattern_fields})\\b\\s*:?\\s*(.*?)(?=\\b(?:{pattern_fields})\\b\\s*:?\\s*|$)'\n",
    "\n",
    "matches = re.findall(pattern, cleaned_data_modified, re.DOTALL)\n",
    "\n",
    "# Build a dictionary from matches; keys are lowercased for consistency.\n",
    "extracted = {key.strip().lower(): value.strip() for key, value in matches}\n",
    "\n",
    "# Make sure each pre-defined field is present in the result. Use None if missing.\n",
    "result_mapping = {}\n",
    "for field in fields_list:\n",
    "    result_mapping[field] = extracted.get(field.lower(), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd43d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Overwrite (ignore) the old df_main completely\n",
    "df_new = pd.DataFrame([result_mapping])\n",
    "\n",
    "print(\"New df_main:\")\n",
    "print(df_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d250eb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval</th>\n",
       "      <th>rpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0012</td>\n",
       "      <td>025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0024</td>\n",
       "      <td>025.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0036</td>\n",
       "      <td>025.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0048</td>\n",
       "      <td>025.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0060</td>\n",
       "      <td>025.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interval    rpm\n",
       "0     0012  025.0\n",
       "1     0024  025.1\n",
       "2     0036  025.1\n",
       "3     0048  025.1\n",
       "4     0060  025.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5e4a366c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# For the primary data, orient 'records' returns a list of row dictionaries.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m df_new\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# For the summary statistics, orient 'index' creates a dictionary keyed by statistic type.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m stats_dict \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_new' is not defined"
     ]
    }
   ],
   "source": [
    "# For the primary data, orient 'records' returns a list of row dictionaries.\n",
    "data_dict = df_new.to_dict(orient='records')\n",
    "# For the summary statistics, orient 'index' creates a dictionary keyed by statistic type.\n",
    "stats_dict = df.to_dict(orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a0cc5ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Combine both dictionaries into one.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m combined \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_dict,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m\"\u001b[39m: stats_dict\n\u001b[0;32m      5\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Combine both dictionaries into one.\n",
    "combined = {\n",
    "    \"data\": data_dict,\n",
    "    \"stats\": stats_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18e07584",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(combined)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combined' is not defined"
     ]
    }
   ],
   "source": [
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0fc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Write the combined data to a JSON file.\n",
    "with open('combined_data.json', 'w') as json_file:\n",
    "    json.dump(combined, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0316cebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
